{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1w9AYcq5R1L"
   },
   "source": [
    "# Big Data Management Project 2:\n",
    "## DESB GRAND CHALLENGE 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OpzgMHds5R1M",
    "outputId": "c2717441-381b-48f5-8e5b-2c43f3ebd6d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shapely\n",
      "  Downloading shapely-2.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.11/site-packages (from shapely) (1.26.4)\n",
      "Downloading shapely-2.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: shapely\n",
      "Successfully installed shapely-2.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, unix_timestamp, col, lag, avg, lead, count, sum as spark_sum\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType, DoubleType, FloatType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gLNNqDSZ5R1O"
   },
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "                    .appName('BDM_Project2')\n",
    "                    .enableHiveSupport()\n",
    "                    .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_NyMxyS5R1O"
   },
   "source": [
    "### Query 0\n",
    "Data Cleansing and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OYAFRgWI5R1O",
    "outputId": "cc41f6c7-b5d7-4ad4-9050-8ac6ca454008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+---------------+----------------+----------+----------------+-----------------+----------+--------+\n",
      "|hack_license                    |pickup_latitude|pickup_longitude|pickup_ts |dropoff_latitude|dropoff_longitude|dropoff_ts|duration|\n",
      "+--------------------------------+---------------+----------------+----------+----------------+-----------------+----------+--------+\n",
      "|77FFDF38272A6006517D53EDA14333E2|40.768005      |-73.9701        |1356998420|40.767834       |-73.969772       |1356998482|62      |\n",
      "|CDCB7729DE07243726FF7BB0BD5D06BF|40.749657      |-73.975441      |1356998414|40.751991       |-73.977333       |1356998497|83      |\n",
      "|7D89374F8E98F30A19F2381EC71A16BA|40.720531      |-74.005165      |1356998440|40.725655       |-74.003929       |1356998500|60      |\n",
      "|E7750A37CAB07D0DFF0AF7E3573AC141|40.716976      |-73.956528      |1356998400|40.715008       |-73.96244        |1356998520|120     |\n",
      "|145038A0CC99D6982D8001BE668154CA|40.790169      |-73.95208       |1356998460|40.794323       |-73.948921       |1356998520|60      |\n",
      "+--------------------------------+---------------+----------------+----------+----------------+-----------------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Execution time 0.4429924488067627\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() # To see the time it takes to execute data transformations\n",
    "\n",
    "# Defining the schema for faster reading of data\n",
    "schema = StructType([\n",
    "    StructField(\"medallion\", StringType(), True),\n",
    "    StructField(\"hack_license\", StringType(), True),\n",
    "    StructField(\"pickup_datetime\", TimestampType(), True),\n",
    "    StructField(\"dropoff_datetime\", TimestampType(), True),\n",
    "    StructField(\"passenger_count\", IntegerType(), True),\n",
    "    StructField(\"trip_distance\", DoubleType(), True),\n",
    "    StructField(\"pickup_longitude\", DoubleType(), True),\n",
    "    StructField(\"pickup_latitude\", DoubleType(), True),\n",
    "    StructField(\"dropoff_longitude\", DoubleType(), True),\n",
    "    StructField(\"dropoff_latitude\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# Creating a single dataframe of all the trip_data files\n",
    "taxi_df_og = (\n",
    "    spark.read\n",
    "    .option(\"header\", True)\n",
    "    .schema(schema)\n",
    "    .csv(\"input/sorted_data.csv\")\n",
    ")\n",
    "\n",
    "# Removing the trips with 0 passengers\n",
    "# Transforming the data (further explained in the project report)\n",
    "taxi_df = taxi_df_og.filter(\n",
    "    (col(\"passenger_count\") > 0) &\n",
    "    (col(\"trip_distance\") > 0) &\n",
    "    (col(\"pickup_longitude\") != col(\"dropoff_longitude\")) &\n",
    "    (col(\"pickup_latitude\") != col(\"dropoff_latitude\"))\n",
    ")\n",
    "\n",
    "# Convert timestamps to Unix format \n",
    "taxi_df = taxi_df.withColumns({\n",
    "    \"pickup_ts\": unix_timestamp(\"pickup_datetime\"),\n",
    "    \"dropoff_ts\": unix_timestamp(\"dropoff_datetime\")\n",
    "}).withColumn(\n",
    "    \"duration\", col(\"dropoff_ts\") - col(\"pickup_ts\")\n",
    ").filter(\n",
    "    (col(\"duration\") > 0) & (col(\"duration\") <= 4 * 60 * 60)\n",
    ").select(\n",
    "    \"hack_license\",\n",
    "    \"pickup_latitude\",\n",
    "    \"pickup_longitude\",\n",
    "    \"pickup_ts\",\n",
    "    \"dropoff_latitude\",\n",
    "    \"dropoff_longitude\",\n",
    "    \"dropoff_ts\",\n",
    "    \"duration\"\n",
    ").dropna()\n",
    "\n",
    "taxi_df.show(5, truncate=False)\n",
    "\n",
    "print(\"Execution time\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIv-IUsW5R1O"
   },
   "source": [
    "### Query 1\n",
    "Frequent Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U31yCwN_5R1P",
    "outputId": "d7cdaaee-fb1e-4347-aef0-55818fbb2b7d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAG1UbBE5R1P"
   },
   "source": [
    "### Query 2\n",
    "Profitable Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7jwl2aoiZKk",
    "outputId": "c108e39e-4048-4671-a393-ccf3cd345d67"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Practice session - Dataframe",
   "notebookOrigID": 1061204080530756,
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
