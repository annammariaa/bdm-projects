{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1w9AYcq5R1L"
   },
   "source": [
    "# Big Data Management Project 1:\n",
    "## Analyzing New York City Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OpzgMHds5R1M",
    "outputId": "c2717441-381b-48f5-8e5b-2c43f3ebd6d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shapely\n",
      "  Using cached shapely-2.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.11/site-packages (from shapely) (1.26.4)\n",
      "Using cached shapely-2.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "Installing collected packages: shapely\n",
      "Successfully installed shapely-2.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AIlRInxc5R1N"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, unix_timestamp, col, lag, avg, lead, count, sum as spark_sum, floor\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType, DoubleType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "from shapely.geometry import shape, Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gLNNqDSZ5R1O"
   },
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "                    .appName('BDM_Project1')\n",
    "                    .enableHiveSupport()\n",
    "                    .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_NyMxyS5R1O"
   },
   "source": [
    "### NYC Borough Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UHCWtjcE5R1O"
   },
   "outputs": [],
   "source": [
    "with open('input/nyc-boroughs.geojson') as f:\n",
    "    geo_data = json.load(f)\n",
    "\n",
    "# Broadcasting data to workers\n",
    "broadcast_geo_data = spark.sparkContext.broadcast(geo_data)\n",
    "\n",
    "# Creating a dictionary of borough codes and polygons within the borough\n",
    "polygons = {}\n",
    "b_names = {} # borough names by code\n",
    "\n",
    "for feature in broadcast_geo_data.value['features']:\n",
    "\n",
    "    code = feature['properties']['boroughCode']\n",
    "    name = feature['properties']['borough']\n",
    "\n",
    "    if code not in polygons:\n",
    "        polygons[code] = []\n",
    "        b_names[code] = name\n",
    "\n",
    "    polygons[code].append(shape(feature['geometry']))\n",
    "\n",
    "# Sorting borough polygons by area\n",
    "for code in polygons:\n",
    "    polygons[code] = sorted(\n",
    "        polygons[code], key=lambda x: x.area, reverse=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ez7SlBkl5R1O"
   },
   "outputs": [],
   "source": [
    "# UDF: longitude, latitude -> borough\n",
    "def get_borough(long, lat):\n",
    "    point = Point(long, lat)\n",
    "\n",
    "    for code, pols in polygons.items():\n",
    "        for polygon in pols:\n",
    "            if polygon.contains(point):\n",
    "                return code\n",
    "\n",
    "    return None\n",
    "\n",
    "get_borough_udf = udf(get_borough, IntegerType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJSJuQQ65R1O"
   },
   "source": [
    "### NYC Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OYAFRgWI5R1O",
    "outputId": "cc41f6c7-b5d7-4ad4-9050-8ac6ca454008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+---------------+----------------+----------+----------------+-----------------+----------+--------+--------------+---------------+\n",
      "|hack_license                    |pickup_latitude|pickup_longitude|pickup_ts |dropoff_latitude|dropoff_longitude|dropoff_ts|duration|pickup_borough|dropoff_borough|\n",
      "+--------------------------------+---------------+----------------+----------+----------------+-----------------+----------+--------+--------------+---------------+\n",
      "|BA96DE419E711691B9445D6A6307C170|40.757977      |-73.978165      |1357053108|40.751171       |-73.989838       |1357053490|382     |1             |1              |\n",
      "|9FD8F69F0804BDB5549F40E9DA1BE472|40.731781      |-74.006683      |1357431515|40.75066        |-73.994499       |1357431774|259     |1             |1              |\n",
      "|9FD8F69F0804BDB5549F40E9DA1BE472|40.73777       |-74.004707      |1357411781|40.726002       |-74.009834       |1357412063|282     |1             |1              |\n",
      "|51EE87E3205C985EF8431D850C786310|40.759945      |-73.974602      |1357602855|40.759388       |-73.984734       |1357603100|245     |1             |1              |\n",
      "|51EE87E3205C985EF8431D850C786310|40.748528      |-73.97625       |1357601103|40.747868       |-74.002586       |1357601664|561     |1             |1              |\n",
      "+--------------------------------+---------------+----------------+----------+----------------+-----------------+----------+--------+--------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Execution time 6.672400951385498\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() # To see the time it takes to execute data transformations\n",
    "\n",
    "# Defining the schema for faster reading of data\n",
    "schema = StructType([\n",
    "    StructField(\"medallion\", StringType(), True),\n",
    "    StructField(\"hack_license\", StringType(), True),\n",
    "    StructField(\"vendor_id\", StringType(), True),\n",
    "    StructField(\"rate_code\", StringType(), True),\n",
    "    StructField(\"store_and_fwd_flag\", StringType(), True),\n",
    "    StructField(\"pickup_datetime\", TimestampType(), True),\n",
    "    StructField(\"dropoff_datetime\", TimestampType(), True),\n",
    "    StructField(\"passenger_count\", StringType(), True),\n",
    "    StructField(\"trip_time_in_secs\", StringType(), True),\n",
    "    StructField(\"trip_distance\", StringType(), True),\n",
    "    StructField(\"pickup_longitude\", DoubleType(), True),\n",
    "    StructField(\"pickup_latitude\", DoubleType(), True),\n",
    "    StructField(\"dropoff_longitude\", DoubleType(), True),\n",
    "    StructField(\"dropoff_latitude\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# Creating a single dataframe of all the trip_data files\n",
    "taxi_df_og = (spark.read\n",
    "             .option(\"sep\", \",\")\n",
    "             .option(\"header\", True)\n",
    "             .schema(schema)\n",
    "             .csv(\"input/trip_data/trip_data_*.csv\")\n",
    "             #.csv([\"input/trip_data/trip_data_1.csv\"])\n",
    "          )\n",
    "\n",
    "# Removing the trips with 0 passengers\n",
    "# Transforming the data (further explained in the project report)\n",
    "taxi_df = taxi_df_og.filter(\n",
    "    (taxi_df_og.passenger_count != \"0\") &\n",
    "    ~(\n",
    "        (taxi_df_og.trip_distance == 0) &\n",
    "        (taxi_df_og.pickup_longitude == taxi_df_og.dropoff_longitude) &\n",
    "        (taxi_df_og.pickup_latitude == taxi_df_og.dropoff_latitude)\n",
    "    )\n",
    ").withColumns({\n",
    "    \"pickup_ts\": unix_timestamp(\"pickup_datetime\", \"dd-MM-yy HH:mm\"),\n",
    "    \"dropoff_ts\": unix_timestamp(\"dropoff_datetime\", \"dd-MM-yy HH:mm\")\n",
    "}).withColumn(\n",
    "    \"duration\", col(\"dropoff_ts\") - col(\"pickup_ts\")\n",
    ").filter(\n",
    "    (col(\"duration\") > 0) & (col(\"duration\") <= 4 * 60 * 60)\n",
    ").select(\n",
    "    \"hack_license\",\n",
    "    \"pickup_latitude\",\n",
    "    \"pickup_longitude\",\n",
    "    \"pickup_ts\",\n",
    "    \"dropoff_latitude\",\n",
    "    \"dropoff_longitude\",\n",
    "    \"dropoff_ts\",\n",
    "    \"duration\"\n",
    ").dropna()\n",
    "\n",
    "# Adding pick up and drop off boroughs to taxi data\n",
    "taxi_df = taxi_df.withColumn(\n",
    "    \"pickup_borough\", get_borough_udf(\"pickup_longitude\", \"pickup_latitude\")\n",
    ").withColumn(\n",
    "    \"dropoff_borough\", get_borough_udf(\"dropoff_longitude\", \"dropoff_latitude\")\n",
    ")\n",
    "taxi_df.show(5, truncate=False)\n",
    "\n",
    "print(\"Execution time\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIv-IUsW5R1O"
   },
   "source": [
    "### Query 1\n",
    "Utilization: idle time per taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U31yCwN_5R1P",
    "outputId": "d7cdaaee-fb1e-4347-aef0-55818fbb2b7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+-------------------+----------+-------------------+\n",
      "|        hack_license|total_idle_time|total_ride_duration|total_time|   utilization_rate|\n",
      "+--------------------+---------------+-------------------+----------+-------------------+\n",
      "|001EEDEA00E57988E...|        2824815|            3997082|   6821897| 0.5859194297421964|\n",
      "|00C2BC1F860FC66BA...|        3476121|            4458427|   7934548| 0.5619005644681966|\n",
      "|013DB7F394A06CD24...|        3156241|            3770415|   6926656| 0.5443340913710742|\n",
      "|01594037EE38FE0D9...|          96540|             114360|    210900| 0.5422475106685632|\n",
      "|015D33FBAB8A7C5CE...|        4319100|            3831240|   8150340| 0.4700711872142757|\n",
      "|01606C9E10D8D0B19...|        3479773|            3549859|   7029632| 0.5049850404686903|\n",
      "|024B2794FF91BF97F...|        2489916|            3175059|   5664975| 0.5604718467424834|\n",
      "|02548BECEDACA82F0...|        4156986|            2832100|   6989086|0.40521750626619846|\n",
      "|02856AFC22881ABCA...|        3082740|            2758680|   5841420| 0.4722618815288063|\n",
      "|02E3C1D2FE5D53C22...|          85142|              71026|    156168| 0.4548050817068798|\n",
      "+--------------------+---------------+-------------------+----------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copy taxi_df dataframe\n",
    "taxi_copy = (\n",
    "    taxi_df\n",
    "    .select(\"hack_license\", \"pickup_ts\", \"dropoff_ts\", \"dropoff_borough\")\n",
    "    .repartition(\"hack_license\")\n",
    ")\n",
    "\n",
    "# Partition by driver and then order by pickup time with Window\n",
    "window_sp = Window.partitionBy(\"hack_license\").orderBy(\"pickup_ts\")\n",
    "\n",
    "# Compute previous dropoff time and idle time\n",
    "taxi_copy = (\n",
    "    taxi_copy.withColumn(\"prev_dropoff_ts\", lag(\"dropoff_ts\").over(window_sp))\n",
    "             .withColumn(\"idle_time\", col(\"pickup_ts\") - col(\"prev_dropoff_ts\"))\n",
    ")\n",
    "\n",
    "# Control that idle time is not over 4h and filter out rows where pickup_ts < prev_dropoff_ts (overlapping trips)\n",
    "taxi_copy = taxi_copy.filter(\n",
    "    (col(\"idle_time\").isNotNull()) &\n",
    "    (col(\"idle_time\") > 0) &\n",
    "    (col(\"idle_time\") <= 4 * 60 * 60)\n",
    ")\n",
    "\n",
    "# Group by driver and calculate total idle time and total ride duration\n",
    "taxi_stats = (\n",
    "    taxi_copy.groupBy(\"hack_license\")\n",
    "    .agg(\n",
    "        spark_sum(\"idle_time\").alias(\"total_idle_time\"),\n",
    "        spark_sum(col(\"dropoff_ts\") - col(\"pickup_ts\")).alias(\"total_ride_duration\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Calculate utilization rate\n",
    "utilization_df = (\n",
    "    taxi_stats.withColumn(\"total_time\", col(\"total_idle_time\") + col(\"total_ride_duration\"))\n",
    "              .withColumn(\"utilization_rate\", col(\"total_ride_duration\") / col(\"total_time\"))\n",
    ")\n",
    "\n",
    "utilization_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|avg_utilization_rate|\n",
      "+--------------------+\n",
      "|    0.50287482780684|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_utilization_rate = utilization_df.agg(avg(\"utilization_rate\").alias(\"avg_utilization_rate\"))\n",
    "\n",
    "# Show the result\n",
    "avg_utilization_rate.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAG1UbBE5R1P"
   },
   "source": [
    "### Query 2\n",
    "The average time it takes for a taxi to find its next fare(trip) per destination borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7jwl2aoiZKk",
    "outputId": "c108e39e-4048-4671-a393-ccf3cd345d67"
   },
   "outputs": [],
   "source": [
    "taxi_df_with_waiting_time = taxi_copy.withColumn(\n",
    "    \"prev_pickup_ts\", lag(\"pickup_ts\").over(window_sp)  # Get previous pickup time\n",
    ").withColumn(\n",
    "    \"waiting_time\", col(\"dropoff_ts\") - col(\"prev_pickup_ts\")  # Calculate waiting time\n",
    ")\n",
    "\n",
    "taxi_df_filtered = taxi_df_with_waiting_time.filter(\n",
    "    (col(\"waiting_time\").isNotNull()) &\n",
    "    (col(\"waiting_time\") > 0) &\n",
    "    (col(\"waiting_time\") <= 4 * 60 * 60)\n",
    ")\n",
    "\n",
    "avg_waiting_time_per_borough = taxi_df_filtered.groupBy(\"dropoff_borough\").agg(\n",
    "    avg(\"waiting_time\").alias(\"avg_waiting_time\")\n",
    ")\n",
    "\n",
    "avg_waiting_time_per_borough.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ems5L6xW5R1P"
   },
   "source": [
    "### Query 3\n",
    "The number of trips that started and ended within the same borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5G0z3FoY5R1P",
    "outputId": "d9bd3951-9735-4b19-e77c-08a4753cd5ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of trips that started and ended in the same borough per borough:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/socket.py\", line 718, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 18\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe number of trips that started and ended in the same borough per borough:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     17\u001B[0m same_borough_trips_named \u001B[38;5;241m=\u001B[39m same_borough_trips_named\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mborough_name\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrip_count\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 18\u001B[0m \u001B[43msame_borough_trips_named\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:947\u001B[0m, in \u001B[0;36mDataFrame.show\u001B[0;34m(self, n, truncate, vertical)\u001B[0m\n\u001B[1;32m    887\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mshow\u001B[39m(\u001B[38;5;28mself\u001B[39m, n: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m20\u001B[39m, truncate: Union[\u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, vertical: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    888\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001B[39;00m\n\u001B[1;32m    889\u001B[0m \n\u001B[1;32m    890\u001B[0m \u001B[38;5;124;03m    .. versionadded:: 1.3.0\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    945\u001B[0m \u001B[38;5;124;03m    name | Bob\u001B[39;00m\n\u001B[1;32m    946\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 947\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_show_string\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtruncate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvertical\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:965\u001B[0m, in \u001B[0;36mDataFrame._show_string\u001B[0;34m(self, n, truncate, vertical)\u001B[0m\n\u001B[1;32m    959\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n\u001B[1;32m    960\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNOT_BOOL\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    961\u001B[0m         message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvertical\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(vertical)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n\u001B[1;32m    962\u001B[0m     )\n\u001B[1;32m    964\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(truncate, \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m truncate:\n\u001B[0;32m--> 965\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshowString\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvertical\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    966\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    967\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1314\u001B[0m args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_args(\u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[0;32m-> 1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1323\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
      "File \u001B[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1038\u001B[0m, in \u001B[0;36mGatewayClient.send_command\u001B[0;34m(self, command, retry, binary)\u001B[0m\n\u001B[1;32m   1036\u001B[0m connection \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_connection()\n\u001B[1;32m   1037\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1038\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1039\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m binary:\n\u001B[1;32m   1040\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m response, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_connection_guard(connection)\n",
      "File \u001B[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:511\u001B[0m, in \u001B[0;36mClientServerConnection.send_command\u001B[0;34m(self, command)\u001B[0m\n\u001B[1;32m    509\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    510\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 511\u001B[0m         answer \u001B[38;5;241m=\u001B[39m smart_decode(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream\u001B[38;5;241m.\u001B[39mreadline()[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m    512\u001B[0m         logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAnswer received: \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(answer))\n\u001B[1;32m    513\u001B[0m         \u001B[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001B[39;00m\n\u001B[1;32m    514\u001B[0m         \u001B[38;5;66;03m# answer before the socket raises an error.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/socket.py:718\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    716\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    717\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 718\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    719\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    720\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Filter df to only include trips that start and end in same borough, group by pickup boroughs\n",
    "same_borough_trips_df = taxi_df.filter(col(\"pickup_borough\") == col(\"dropoff_borough\")).groupBy(\"pickup_borough\").agg(count(\"*\").alias(\"trip_count\"))\n",
    "\n",
    "# Put borough names and codes in new df to be used in next step\n",
    "borough_names_df = spark.createDataFrame([(code, name) for code, name in b_names.items()],\n",
    "                                        [\"borough_code\", \"borough_name\"])\n",
    "\n",
    "# Replace borough codes w borough names\n",
    "same_borough_trips_named = same_borough_trips_df.join(\n",
    "    borough_names_df,\n",
    "    same_borough_trips_df.pickup_borough == borough_names_df.borough_code,\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "# Show results'\n",
    "print(\"The number of trips that started and ended in the same borough per borough:\")\n",
    "same_borough_trips_named = same_borough_trips_named.select(\"borough_name\", \"trip_count\")\n",
    "same_borough_trips_named.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0_xMVVE5R1P"
   },
   "source": [
    "### Query 4\n",
    "The number of trips that started in one borough and ended in another one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-9kcTosn5R1P",
    "outputId": "63c32182-67e1-4f35-daba-6f0315617b18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of trips that started and ended in the different boroughs per borough:\n",
      "+-------------------+--------------------+----------+\n",
      "|pickup_borough_name|dropoff_borough_name|trip_count|\n",
      "+-------------------+--------------------+----------+\n",
      "|          Manhattan|              Queens|    460647|\n",
      "|          Manhattan|            Brooklyn|    439578|\n",
      "|             Queens|           Manhattan|    402290|\n",
      "|           Brooklyn|           Manhattan|    118422|\n",
      "|             Queens|            Brooklyn|     81561|\n",
      "|          Manhattan|               Bronx|     50053|\n",
      "|           Brooklyn|              Queens|     17328|\n",
      "|             Queens|               Bronx|      9752|\n",
      "|              Bronx|           Manhattan|      2890|\n",
      "|          Manhattan|       Staten Island|      1924|\n",
      "|             Queens|       Staten Island|       619|\n",
      "|           Brooklyn|               Bronx|       498|\n",
      "|              Bronx|              Queens|       271|\n",
      "|           Brooklyn|       Staten Island|       128|\n",
      "|              Bronx|            Brooklyn|        80|\n",
      "|      Staten Island|           Manhattan|        41|\n",
      "|      Staten Island|            Brooklyn|         8|\n",
      "|      Staten Island|              Queens|         6|\n",
      "|              Bronx|       Staten Island|         2|\n",
      "+-------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "different_borough_trips_df = (taxi_df.filter(col(\"pickup_borough\") != col(\"dropoff_borough\")).groupBy(\"pickup_borough\", \"dropoff_borough\").agg(count(\"*\").alias(\"trip_count\")))\n",
    "\n",
    "# Create a separate aliased df for pickup and dropoff borough names\n",
    "borough_names_pickup = borough_names_df.alias(\"pickup\")\n",
    "borough_names_dropoff = borough_names_df.alias(\"dropoff\")\n",
    "\n",
    "# First join for pickup borough names\n",
    "pickup_joined = different_borough_trips_df.join(\n",
    "    borough_names_pickup,\n",
    "    different_borough_trips_df.pickup_borough == borough_names_pickup.borough_code,\n",
    "    \"left\"\n",
    ").withColumnRenamed(\"borough_name\", \"pickup_borough_name\")\n",
    "\n",
    "# Second join for dropoff borough names\n",
    "final_joined = pickup_joined.join(\n",
    "    borough_names_dropoff,\n",
    "    pickup_joined.dropoff_borough == borough_names_dropoff.borough_code,\n",
    "    \"left\"\n",
    ").withColumnRenamed(\"borough_name\", \"dropoff_borough_name\")\n",
    "\n",
    "# Show results\n",
    "print(\"The number of trips that started and ended in the different boroughs per borough:\")\n",
    "result = final_joined.select(\"pickup_borough_name\", \"dropoff_borough_name\", \"trip_count\")\n",
    "result.orderBy(col(\"trip_count\").desc()).show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Practice session - Dataframe",
   "notebookOrigID": 1061204080530756,
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}